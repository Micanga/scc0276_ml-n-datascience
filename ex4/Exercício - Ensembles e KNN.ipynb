{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Exercício - Ensembles e KNN.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"art5PFADYAxu","colab_type":"text"},"source":["# Exercício\n","## Ensembles e K-nearest neighbors\n","### Alunos (Nome e número usp):\n","- Fernanda Tostes Marana (4471070)\n","- Matheus Aparecido do Carmo Alves (9791114)\n","- Thais Bianchini (9791010)\n"," \n","---"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aFbyaeLeBAEf"},"source":["Para esse exercício, vamos utilizar novamente o dataset [Breast Cancer Winsconsin](https://scikit-learn.org/stable/datasets/index.html#breast-cancer-dataset)."]},{"cell_type":"markdown","metadata":{"id":"4-MKSaenTIO9","colab_type":"text"},"source":["\n","\n","---\n","\n","### Questão 1.\n","\n","Carregue o dataset Breast Cancer do módulo `sklearn.datasets` e normalize os dados."]},{"cell_type":"code","metadata":{"id":"BlWsvQIvWsJt","colab_type":"code","outputId":"b95b7848-aa0e-49c3-d510-b0d168b043cb","executionInfo":{"status":"ok","timestamp":1587688207520,"user_tz":180,"elapsed":1106,"user":{"displayName":"Matheus Aparecido do Carmo Alves","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifW1wUWnNp1UXdy3bEf9lvzlru76frL-kbHoYkQg=s64","userId":"04519095900823812620"}},"colab":{"base_uri":"https://localhost:8080/","height":473}},"source":["import numpy as np\n","import pandas as pd\n","from sklearn import datasets\n","from sklearn.preprocessing import StandardScaler\n","\n","# 1. Loading breast cancer dataset\n","breast_cancer = datasets.load_breast_cancer()\n","X = breast_cancer['data']\n","y = breast_cancer['target']\n","\n","# 2. Normalising the data\n","# - here we are standardising features by removing the mean and scaling to unit \n","# variance, i.e.: z = (x-u)/s, where x is the data vector, u is the mean and\n","# s is the standard deviation \n","scaler = StandardScaler()\n","X = scaler.fit_transform(X,y)\n","\n","# 3. Presenting the normalised dataset\n","data = np.column_stack((X,y))\n","feature_names = list(breast_cancer['feature_names'])\n","feature_names.append('class')\n","breast_cancer_df = pd.DataFrame(data,columns=feature_names)\n","breast_cancer_df"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>mean radius</th>\n","      <th>mean texture</th>\n","      <th>mean perimeter</th>\n","      <th>mean area</th>\n","      <th>mean smoothness</th>\n","      <th>mean compactness</th>\n","      <th>mean concavity</th>\n","      <th>mean concave points</th>\n","      <th>mean symmetry</th>\n","      <th>mean fractal dimension</th>\n","      <th>radius error</th>\n","      <th>texture error</th>\n","      <th>perimeter error</th>\n","      <th>area error</th>\n","      <th>smoothness error</th>\n","      <th>compactness error</th>\n","      <th>concavity error</th>\n","      <th>concave points error</th>\n","      <th>symmetry error</th>\n","      <th>fractal dimension error</th>\n","      <th>worst radius</th>\n","      <th>worst texture</th>\n","      <th>worst perimeter</th>\n","      <th>worst area</th>\n","      <th>worst smoothness</th>\n","      <th>worst compactness</th>\n","      <th>worst concavity</th>\n","      <th>worst concave points</th>\n","      <th>worst symmetry</th>\n","      <th>worst fractal dimension</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.097064</td>\n","      <td>-2.073335</td>\n","      <td>1.269934</td>\n","      <td>0.984375</td>\n","      <td>1.568466</td>\n","      <td>3.283515</td>\n","      <td>2.652874</td>\n","      <td>2.532475</td>\n","      <td>2.217515</td>\n","      <td>2.255747</td>\n","      <td>2.489734</td>\n","      <td>-0.565265</td>\n","      <td>2.833031</td>\n","      <td>2.487578</td>\n","      <td>-0.214002</td>\n","      <td>1.316862</td>\n","      <td>0.724026</td>\n","      <td>0.660820</td>\n","      <td>1.148757</td>\n","      <td>0.907083</td>\n","      <td>1.886690</td>\n","      <td>-1.359293</td>\n","      <td>2.303601</td>\n","      <td>2.001237</td>\n","      <td>1.307686</td>\n","      <td>2.616665</td>\n","      <td>2.109526</td>\n","      <td>2.296076</td>\n","      <td>2.750622</td>\n","      <td>1.937015</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.829821</td>\n","      <td>-0.353632</td>\n","      <td>1.685955</td>\n","      <td>1.908708</td>\n","      <td>-0.826962</td>\n","      <td>-0.487072</td>\n","      <td>-0.023846</td>\n","      <td>0.548144</td>\n","      <td>0.001392</td>\n","      <td>-0.868652</td>\n","      <td>0.499255</td>\n","      <td>-0.876244</td>\n","      <td>0.263327</td>\n","      <td>0.742402</td>\n","      <td>-0.605351</td>\n","      <td>-0.692926</td>\n","      <td>-0.440780</td>\n","      <td>0.260162</td>\n","      <td>-0.805450</td>\n","      <td>-0.099444</td>\n","      <td>1.805927</td>\n","      <td>-0.369203</td>\n","      <td>1.535126</td>\n","      <td>1.890489</td>\n","      <td>-0.375612</td>\n","      <td>-0.430444</td>\n","      <td>-0.146749</td>\n","      <td>1.087084</td>\n","      <td>-0.243890</td>\n","      <td>0.281190</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.579888</td>\n","      <td>0.456187</td>\n","      <td>1.566503</td>\n","      <td>1.558884</td>\n","      <td>0.942210</td>\n","      <td>1.052926</td>\n","      <td>1.363478</td>\n","      <td>2.037231</td>\n","      <td>0.939685</td>\n","      <td>-0.398008</td>\n","      <td>1.228676</td>\n","      <td>-0.780083</td>\n","      <td>0.850928</td>\n","      <td>1.181336</td>\n","      <td>-0.297005</td>\n","      <td>0.814974</td>\n","      <td>0.213076</td>\n","      <td>1.424827</td>\n","      <td>0.237036</td>\n","      <td>0.293559</td>\n","      <td>1.511870</td>\n","      <td>-0.023974</td>\n","      <td>1.347475</td>\n","      <td>1.456285</td>\n","      <td>0.527407</td>\n","      <td>1.082932</td>\n","      <td>0.854974</td>\n","      <td>1.955000</td>\n","      <td>1.152255</td>\n","      <td>0.201391</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.768909</td>\n","      <td>0.253732</td>\n","      <td>-0.592687</td>\n","      <td>-0.764464</td>\n","      <td>3.283553</td>\n","      <td>3.402909</td>\n","      <td>1.915897</td>\n","      <td>1.451707</td>\n","      <td>2.867383</td>\n","      <td>4.910919</td>\n","      <td>0.326373</td>\n","      <td>-0.110409</td>\n","      <td>0.286593</td>\n","      <td>-0.288378</td>\n","      <td>0.689702</td>\n","      <td>2.744280</td>\n","      <td>0.819518</td>\n","      <td>1.115007</td>\n","      <td>4.732680</td>\n","      <td>2.047511</td>\n","      <td>-0.281464</td>\n","      <td>0.133984</td>\n","      <td>-0.249939</td>\n","      <td>-0.550021</td>\n","      <td>3.394275</td>\n","      <td>3.893397</td>\n","      <td>1.989588</td>\n","      <td>2.175786</td>\n","      <td>6.046041</td>\n","      <td>4.935010</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.750297</td>\n","      <td>-1.151816</td>\n","      <td>1.776573</td>\n","      <td>1.826229</td>\n","      <td>0.280372</td>\n","      <td>0.539340</td>\n","      <td>1.371011</td>\n","      <td>1.428493</td>\n","      <td>-0.009560</td>\n","      <td>-0.562450</td>\n","      <td>1.270543</td>\n","      <td>-0.790244</td>\n","      <td>1.273189</td>\n","      <td>1.190357</td>\n","      <td>1.483067</td>\n","      <td>-0.048520</td>\n","      <td>0.828471</td>\n","      <td>1.144205</td>\n","      <td>-0.361092</td>\n","      <td>0.499328</td>\n","      <td>1.298575</td>\n","      <td>-1.466770</td>\n","      <td>1.338539</td>\n","      <td>1.220724</td>\n","      <td>0.220556</td>\n","      <td>-0.313395</td>\n","      <td>0.613179</td>\n","      <td>0.729259</td>\n","      <td>-0.868353</td>\n","      <td>-0.397100</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>564</th>\n","      <td>2.110995</td>\n","      <td>0.721473</td>\n","      <td>2.060786</td>\n","      <td>2.343856</td>\n","      <td>1.041842</td>\n","      <td>0.219060</td>\n","      <td>1.947285</td>\n","      <td>2.320965</td>\n","      <td>-0.312589</td>\n","      <td>-0.931027</td>\n","      <td>2.782080</td>\n","      <td>0.071025</td>\n","      <td>2.379583</td>\n","      <td>2.604187</td>\n","      <td>1.086384</td>\n","      <td>0.191805</td>\n","      <td>0.666001</td>\n","      <td>2.067178</td>\n","      <td>-1.138416</td>\n","      <td>0.167980</td>\n","      <td>1.901185</td>\n","      <td>0.117700</td>\n","      <td>1.752563</td>\n","      <td>2.015301</td>\n","      <td>0.378365</td>\n","      <td>-0.273318</td>\n","      <td>0.664512</td>\n","      <td>1.629151</td>\n","      <td>-1.360158</td>\n","      <td>-0.709091</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>565</th>\n","      <td>1.704854</td>\n","      <td>2.085134</td>\n","      <td>1.615931</td>\n","      <td>1.723842</td>\n","      <td>0.102458</td>\n","      <td>-0.017833</td>\n","      <td>0.693043</td>\n","      <td>1.263669</td>\n","      <td>-0.217664</td>\n","      <td>-1.058611</td>\n","      <td>1.300499</td>\n","      <td>2.260938</td>\n","      <td>1.156857</td>\n","      <td>1.291565</td>\n","      <td>-0.424010</td>\n","      <td>-0.069758</td>\n","      <td>0.252202</td>\n","      <td>0.808431</td>\n","      <td>-0.189161</td>\n","      <td>-0.490556</td>\n","      <td>1.536720</td>\n","      <td>2.047399</td>\n","      <td>1.421940</td>\n","      <td>1.494959</td>\n","      <td>-0.691230</td>\n","      <td>-0.394820</td>\n","      <td>0.236573</td>\n","      <td>0.733827</td>\n","      <td>-0.531855</td>\n","      <td>-0.973978</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>566</th>\n","      <td>0.702284</td>\n","      <td>2.045574</td>\n","      <td>0.672676</td>\n","      <td>0.577953</td>\n","      <td>-0.840484</td>\n","      <td>-0.038680</td>\n","      <td>0.046588</td>\n","      <td>0.105777</td>\n","      <td>-0.809117</td>\n","      <td>-0.895587</td>\n","      <td>0.184892</td>\n","      <td>-0.257371</td>\n","      <td>0.276693</td>\n","      <td>0.180698</td>\n","      <td>-0.379342</td>\n","      <td>0.661277</td>\n","      <td>0.510827</td>\n","      <td>0.612157</td>\n","      <td>-0.891416</td>\n","      <td>0.036727</td>\n","      <td>0.561361</td>\n","      <td>1.374854</td>\n","      <td>0.579001</td>\n","      <td>0.427906</td>\n","      <td>-0.809587</td>\n","      <td>0.350735</td>\n","      <td>0.326767</td>\n","      <td>0.414069</td>\n","      <td>-1.104549</td>\n","      <td>-0.318409</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>567</th>\n","      <td>1.838341</td>\n","      <td>2.336457</td>\n","      <td>1.982524</td>\n","      <td>1.735218</td>\n","      <td>1.525767</td>\n","      <td>3.272144</td>\n","      <td>3.296944</td>\n","      <td>2.658866</td>\n","      <td>2.137194</td>\n","      <td>1.043695</td>\n","      <td>1.157935</td>\n","      <td>0.686088</td>\n","      <td>1.438530</td>\n","      <td>1.009503</td>\n","      <td>-0.173000</td>\n","      <td>2.017716</td>\n","      <td>1.302285</td>\n","      <td>0.785721</td>\n","      <td>0.326634</td>\n","      <td>0.904057</td>\n","      <td>1.961239</td>\n","      <td>2.237926</td>\n","      <td>2.303601</td>\n","      <td>1.653171</td>\n","      <td>1.430427</td>\n","      <td>3.904848</td>\n","      <td>3.197605</td>\n","      <td>2.289985</td>\n","      <td>1.919083</td>\n","      <td>2.219635</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>568</th>\n","      <td>-1.808401</td>\n","      <td>1.221792</td>\n","      <td>-1.814389</td>\n","      <td>-1.347789</td>\n","      <td>-3.112085</td>\n","      <td>-1.150752</td>\n","      <td>-1.114873</td>\n","      <td>-1.261820</td>\n","      <td>-0.820070</td>\n","      <td>-0.561032</td>\n","      <td>-0.070279</td>\n","      <td>0.383092</td>\n","      <td>-0.157449</td>\n","      <td>-0.466152</td>\n","      <td>0.049342</td>\n","      <td>-1.163516</td>\n","      <td>-1.057501</td>\n","      <td>-1.913447</td>\n","      <td>0.752830</td>\n","      <td>-0.382754</td>\n","      <td>-1.410893</td>\n","      <td>0.764190</td>\n","      <td>-1.432735</td>\n","      <td>-1.075813</td>\n","      <td>-1.859019</td>\n","      <td>-1.207552</td>\n","      <td>-1.305831</td>\n","      <td>-1.745063</td>\n","      <td>-0.048138</td>\n","      <td>-0.751207</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>569 rows × 31 columns</p>\n","</div>"],"text/plain":["     mean radius  mean texture  ...  worst fractal dimension  class\n","0       1.097064     -2.073335  ...                 1.937015    0.0\n","1       1.829821     -0.353632  ...                 0.281190    0.0\n","2       1.579888      0.456187  ...                 0.201391    0.0\n","3      -0.768909      0.253732  ...                 4.935010    0.0\n","4       1.750297     -1.151816  ...                -0.397100    0.0\n","..           ...           ...  ...                      ...    ...\n","564     2.110995      0.721473  ...                -0.709091    0.0\n","565     1.704854      2.085134  ...                -0.973978    0.0\n","566     0.702284      2.045574  ...                -0.318409    0.0\n","567     1.838341      2.336457  ...                 2.219635    0.0\n","568    -1.808401      1.221792  ...                -0.751207    1.0\n","\n","[569 rows x 31 columns]"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"37u00oF9wviW","colab_type":"text"},"source":["\n","\n","---\n","\n","### Questão 2.\n","\n","Aqui definiremos funções que serão utilizadas para simplificar as operações que faremos posteriormente. Dessa forma, implemente as funções abaixo:\n","\n","*   A função `get_mean_accuracy(model, X, y)` recebe um modelo `model` e um conjunto de atributos `X` e labels `y`. Ela deve calcular a acurácia do modelo utilizando 10-fold cross-validation estratificado e retornar a acurácia média dos 10 folds\n","*   A função `evaluate_models(models, X, y)` recebe um conjunto de modelos definidos por um dicionário e exibe, para cada modelo, seu nome seguido da sua acurácia (calculada com a função `get_mean_accuracy`). Um exemplo de saída para o dicionário `exemplo` abaixo seria:\n","> A acurácia do modelo \"Knn (n_neighbors = 5)\" é 85.00%\n",">\n","> A acurácia do modelo \"DT (gini)\" é 80.00%\n","\n","*   Finalmente, implemente a função `create_name_list(models)`. Essa função deve receber um dicionário e retornar uma lista contendo, para cada elemento do dicionário, uma tupla (chave, valor). Para o dicionário `exemplo`, essa função retornaria:\n","> `[ ('Knn (n_neighbors = 5)', KNeighborsClassifier(n_neighbors=5)), ('DT (gini)', DecisionTreeClassifier(criterion=\"gini\"))]`\n","\n","\n","```\n","exemplo = {\n","    'Knn (n_neighbors = 5)': KNeighborsClassifier(n_neighbors=5),\n","    'DT (gini)': DecisionTreeClassifier(criterion=\"gini\"),\n","}\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"8eSOrXmJy4oH","colab_type":"code","colab":{}},"source":["from numpy import mean\n","from sklearn.model_selection import cross_validate\n","\n","def get_mean_accuracy(model, X, y):\n","  # Applying the stratified 10-fold cross-valitation\n","  metrics = cross_validate(model, X, y, cv=10)\n","\n","  # Returning the mean accuracy score\n","  return(mean(metrics['test_score'])) \n","\n","def evaluate_models(models, X, y):\n","  for (model_name,model) in models:\n","    print('A acurácia do modelo \\\"'+str(model_name)+'\\\" é '+\\\n","          str(np.round(100*get_mean_accuracy(model,X,y),4))+'%')\n","\n","def create_name_list(models):\n","  list1 = [(k, v) for k, v in models.items()]\n","  return (list1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LOITu6JQ3j1J","colab_type":"text"},"source":["\n","\n","---\n","\n","### Questão 3.\n","\n","Defina modelos de SVM (`sklearn.svm.SVC`) e MLP (`sklearn.neural_network.MLPClassifier`) para servir de *baseline* de comparação para modelos futuros. Para isso, teste ao menos 3 configurações de SVM e 3 configurações de MLP. Sua baseline será a melhor acurácia (utilizando 10-fold cross-validation estratificado) entre essas configurações. Utilize as funções definidas na Questão 2 quando necessário."]},{"cell_type":"code","metadata":{"id":"HxaBVuUP6bqe","colab_type":"code","outputId":"28d23fd5-2a34-42f2-af46-1ed695b2147d","executionInfo":{"status":"ok","timestamp":1587688213276,"user_tz":180,"elapsed":6821,"user":{"displayName":"Matheus Aparecido do Carmo Alves","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifW1wUWnNp1UXdy3bEf9lvzlru76frL-kbHoYkQg=s64","userId":"04519095900823812620"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["from sklearn.neural_network import MLPClassifier\n","from sklearn.svm import SVC\n","\n","experiments = { \n","    \"SVM Linear\" : SVC(kernel='poly',degree=1,probability=True),\n","    \"SVM 3-Poly\" : SVC(kernel='poly',degree=3,probability=True),\n","    \"SVM 9-Poly\" : SVC(kernel='poly',degree=9,probability=True),\n","    \"MLP 3-HL\" : MLPClassifier(hidden_layer_sizes=(30,30,30,),solver='lbfgs'),\n","    \"MLP 6-HL\" : MLPClassifier(hidden_layer_sizes=(30,30,30,30,30,30,),solver='lbfgs'),  \n","    \"MLP 9-HL\" : MLPClassifier(hidden_layer_sizes=(30,30,30,30,30,30,30,30,30,),solver='lbfgs'),\n","}\n","list_ready = create_name_list(experiments)\n","evaluate_models(list_ready,X,y)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["A acurácia do modelo \"SVM Linear\" é 97.713%\n","A acurácia do modelo \"SVM 3-Poly\" é 90.3383%\n","A acurácia do modelo \"SVM 9-Poly\" é 79.2638%\n","A acurácia do modelo \"MLP 3-HL\" é 97.3622%\n","A acurácia do modelo \"MLP 6-HL\" é 95.4323%\n","A acurácia do modelo \"MLP 9-HL\" é 90.1598%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jP8nyb4W4XyL","colab_type":"text"},"source":["\n","\n","---\n","\n","### Questão 4.\n","\n","Agora defina dois dicionários de classificadores. Um dicionário deve conter apenas classificadores KNN (`sklearn.neighbors.KNeighborsClassifier`), enquanto o outro deve conter apenas classificadores DT (`sklearn.tree.DecisionTreeClassifier`). Crie ao menos 3 configurações diferentes para cada tipo de classificador. Depois calcule e exiba a acurácia de cada configuração criada utilizando 10-fold cross-validation estratificado."]},{"cell_type":"code","metadata":{"id":"a5x_mhGP6cVc","colab_type":"code","outputId":"c9bab1a0-b659-4b2c-dfd1-e8ae9796d0af","executionInfo":{"status":"ok","timestamp":1587688214092,"user_tz":180,"elapsed":7624,"user":{"displayName":"Matheus Aparecido do Carmo Alves","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifW1wUWnNp1UXdy3bEf9lvzlru76frL-kbHoYkQg=s64","userId":"04519095900823812620"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","\n","experiments_knn = { \n","    \"KNN 10-NN\" : KNeighborsClassifier(n_neighbors=10),\n","    \"KNN 25-NN\" : KNeighborsClassifier(n_neighbors=25),\n","    \"KNN 50-NN\" : KNeighborsClassifier(n_neighbors=50),\n","}\n","experiments_dt = { \n","    \"DTC 10-MD (gini)\" : DecisionTreeClassifier(criterion='gini',max_depth=10),\n","    \"DTC 10-MD (entropy)\" : DecisionTreeClassifier(criterion='entropy',max_depth=10),\n","    \"DTC 25-MD (gini)\" : DecisionTreeClassifier(criterion='gini',max_depth=25),\n","    \"DTC 25-MD (entropy)\" : DecisionTreeClassifier(criterion='entropy',max_depth=25),\n","    \"DTC 50-MD (gini)\" : DecisionTreeClassifier(criterion='gini',max_depth=50),\n","    \"DTC 50-MD (entropy)\" : DecisionTreeClassifier(criterion='entropy',max_depth=50),\n","}\n","\n","# Testing knn models\n","list_ready = create_name_list(experiments_knn)\n","evaluate_models(list_ready,X,y)\n","\n","# Testing dt models\n","list_ready = create_name_list(experiments_dt)\n","evaluate_models(list_ready,X,y)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["A acurácia do modelo \"KNN 10-NN\" é 97.0113%\n","A acurácia do modelo \"KNN 25-NN\" é 95.6078%\n","A acurácia do modelo \"KNN 50-NN\" é 95.4323%\n","A acurácia do modelo \"DTC 10-MD (gini)\" é 90.8741%\n","A acurácia do modelo \"DTC 10-MD (entropy)\" é 92.7882%\n","A acurácia do modelo \"DTC 25-MD (gini)\" é 91.2187%\n","A acurácia do modelo \"DTC 25-MD (entropy)\" é 92.7851%\n","A acurácia do modelo \"DTC 50-MD (gini)\" é 91.3972%\n","A acurácia do modelo \"DTC 50-MD (entropy)\" é 92.9637%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WPXfbaMM6dcP","colab_type":"text"},"source":["\n","\n","---\n","\n","### Questão 5.\n","\n","Agora você deve definir um dicionário contendo diferentes configurações de ensembles a serem testados. Utilize as classes `StackingClassifier`, `AdaBoostClassifier` e `VotingClassifier` do módulo `sklearn.ensemble` (fique a vontade para escolher outros tipos de ensembles desse mesmo módulo). Crie pelo menos 5 configurações diferentes tomando como estimadores os modelos definidos na Questão 4. Calcule a acurácia de cada configuração de ensemble. \n","\n","Obs.: Lembre-se de utilizar as funções definidas anteriormente"]},{"cell_type":"code","metadata":{"id":"fVvqvLOi6M9Z","colab_type":"code","outputId":"796a602d-71e3-493f-98c8-924c20feffc5","executionInfo":{"status":"ok","timestamp":1587688757384,"user_tz":180,"elapsed":29663,"user":{"displayName":"Matheus Aparecido do Carmo Alves","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GifW1wUWnNp1UXdy3bEf9lvzlru76frL-kbHoYkQg=s64","userId":"04519095900823812620"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["from sklearn.ensemble import StackingClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import VotingClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","\n","estimators = [('SVM Linear',experiments['SVM Linear']),\\\n","              ('MLP 3-HL',experiments['MLP 3-HL']),\\\n","              ('KNN 10-NN',experiments_knn['KNN 10-NN']),\\\n","              ('DTC 10-MD (entropy)',experiments_dt['DTC 10-MD (entropy)'])]\n","\n","experiments_ens = { \n","    \"SC PP\" : StackingClassifier(estimators,cv=10,stack_method='predict_proba'),\n","    \"SC P \" : StackingClassifier(estimators,cv=10,stack_method='predict'),\n","    \"ABC 1.0-LR\" : AdaBoostClassifier( n_estimators=50, learning_rate=1.0),\n","    \"ABC 0.7-LR\" : AdaBoostClassifier( n_estimators=50, learning_rate=0.7),\n","    \"ABC 0.5-LR\" : AdaBoostClassifier( n_estimators=50, learning_rate=0.5),\n","    \"VC Soft\" : VotingClassifier(estimators,voting='soft'),\n","    \"VC Hard\" : VotingClassifier(estimators,voting='hard'),\n","}\n","\n","list_ready = create_name_list(experiments_ens)\n","evaluate_models(list_ready,X,y)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["A acurácia do modelo \"SC PP\" é 98.4148%\n","A acurácia do modelo \"SC P \" é 97.5376%\n","A acurácia do modelo \"ABC 1.0-LR\" é 96.131%\n","A acurácia do modelo \"ABC 0.7-LR\" é 96.6604%\n","A acurácia do modelo \"ABC 0.5-LR\" é 95.9586%\n","A acurácia do modelo \"VC Soft\" é 97.5376%\n","A acurácia do modelo \"VC Hard\" é 97.005%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XqIS0YMFAg4V","colab_type":"text"},"source":["\n","\n","---\n","\n","### Questão 6. \n","\n","Discuta as acurácias obtidas nas Questões 3, 4 e 5. Houve algum ganho ao utilizar Ensembles? Em qual situação houve maior ganho?"]},{"cell_type":"markdown","metadata":{"id":"aLz4W1eIA1dR","colab_type":"text"},"source":["**RESPOSTA:**\n","\n","Resguardando as acurácias obtidas nas Questões 3, 4 e 5, temos que as melhores classificações de cada modelo foram:\n","\n","* **SVM Linear :** 97.713%\n","* **MLP 3-HL :** 95.0815%\n","* **KNN 10-NN :** 97.0113%\n","* **DTC 10-MD (entropy):** 93.6779%\n","\n","Estes melhores resultados guiaram a decisão do conjunto de estimadores a serem acoplados nos Ensembles.\n","\n","Ao se utilizar estes métodos sozinhos, como classificadores (considerando as arquiteturas definidas neste exercício), alcançou-se a melhor acurácia com a aplicação da SVM Linear sobre o problema (97.713% de acurácia).\n","\n","A partir da aplicação de Ensembles, foi possível aprimorar esse resultado significativamente, alcançando uma acúracia maior que 98% na utilização do método de Stacking como Ensemble e classificador final (arquitetura \"SC PP\"), podendo variar um pouco devido a natureza de aleatorização do algoritmo.\n","Esta melhora era esperada, dada a natureza e funcionamento de Ensembles.\n","\n","De maneira direta, todos os Ensambles garantiram uma melhora na classificação final para algum dos classificadores utilizados. O que mais se aprimorou foi o modelo DTC 10-MD que antes apresentava um menor taxa de acurácia em seus resultados. Adicionalmente, a situação que garantiu o maior ganho foi a utilização da arquitetura \"SC PP\" (como comentado anteriormente).\n","\n","Desta forma, pode-se observar que existe ganho na aplicação de Ensembles, sendo necessário somente estudá-los e modelá-los para melhorar o resultado para o problema como um todo.\n"]},{"cell_type":"code","metadata":{"id":"upZKEDstmgZC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}