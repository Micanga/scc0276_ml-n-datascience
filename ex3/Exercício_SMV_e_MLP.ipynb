{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Exercício_SMV_e_MLP.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"art5PFADYAxu","colab_type":"text"},"source":["# Exercício\n","## Suport Vector Machines e Multi-Layer Perceptron\n","### Alunos (Nome e número usp):\n","- Fernanda Tostes Marana (4471070)\n","- Matheus Aparecido do Carmo Alves (9791114)\n","- Thais Bianchini (9791010)\n","---"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aFbyaeLeBAEf"},"source":["Para esse exercício, vamos utilizar o dataset [Wine](https://archive.ics.uci.edu/ml/datasets/Wine). Nesse dataset foram colhidas amostras de 3 tipos de vinhos. Cada amostra conta com 13 variáveis descritivas, tais como conteúdo alcoolico, fenóides etc. Ao todo são 178 amostras."]},{"cell_type":"markdown","metadata":{"id":"4-MKSaenTIO9","colab_type":"text"},"source":["\n","\n","---\n","\n","### Questão 1.\n","Importe o dataset através da classe `sklearn.datasets.load_wine()`. Para garantir uma melhor performance dos algoritmos, faça o preprocessamento desses dados através da classe `sklearn.preprocessing.scale`.\n"]},{"cell_type":"code","metadata":{"id":"BlWsvQIvWsJt","colab_type":"code","outputId":"29a89013-9280-4d58-fe83-628db9f9da64","executionInfo":{"status":"ok","timestamp":1586535990592,"user_tz":180,"elapsed":2313,"user":{"displayName":"Matheus Aparecido do Carmo Alves","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GggQ0cnRDkbIVXrd3dqDLpYEUKIr45sRt4MbXAsFg=s64","userId":"02630764298191608861"}},"colab":{"base_uri":"https://localhost:8080/","height":439}},"source":["import pandas as pd\n","from sklearn.datasets import load_wine\n","from sklearn.preprocessing import scale\n","\n","# Loading the dataset\n","wine_dataset = load_wine()\n","\n","# Scaling the data (preprocessing)\n","wine_data = scale(wine_dataset.data)\n","\n","# Presenting the dataset (scaled)\n","pd.DataFrame(wine_data,columns=wine_dataset.feature_names)"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>alcohol</th>\n","      <th>malic_acid</th>\n","      <th>ash</th>\n","      <th>alcalinity_of_ash</th>\n","      <th>magnesium</th>\n","      <th>total_phenols</th>\n","      <th>flavanoids</th>\n","      <th>nonflavanoid_phenols</th>\n","      <th>proanthocyanins</th>\n","      <th>color_intensity</th>\n","      <th>hue</th>\n","      <th>od280/od315_of_diluted_wines</th>\n","      <th>proline</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.518613</td>\n","      <td>-0.562250</td>\n","      <td>0.232053</td>\n","      <td>-1.169593</td>\n","      <td>1.913905</td>\n","      <td>0.808997</td>\n","      <td>1.034819</td>\n","      <td>-0.659563</td>\n","      <td>1.224884</td>\n","      <td>0.251717</td>\n","      <td>0.362177</td>\n","      <td>1.847920</td>\n","      <td>1.013009</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.246290</td>\n","      <td>-0.499413</td>\n","      <td>-0.827996</td>\n","      <td>-2.490847</td>\n","      <td>0.018145</td>\n","      <td>0.568648</td>\n","      <td>0.733629</td>\n","      <td>-0.820719</td>\n","      <td>-0.544721</td>\n","      <td>-0.293321</td>\n","      <td>0.406051</td>\n","      <td>1.113449</td>\n","      <td>0.965242</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.196879</td>\n","      <td>0.021231</td>\n","      <td>1.109334</td>\n","      <td>-0.268738</td>\n","      <td>0.088358</td>\n","      <td>0.808997</td>\n","      <td>1.215533</td>\n","      <td>-0.498407</td>\n","      <td>2.135968</td>\n","      <td>0.269020</td>\n","      <td>0.318304</td>\n","      <td>0.788587</td>\n","      <td>1.395148</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.691550</td>\n","      <td>-0.346811</td>\n","      <td>0.487926</td>\n","      <td>-0.809251</td>\n","      <td>0.930918</td>\n","      <td>2.491446</td>\n","      <td>1.466525</td>\n","      <td>-0.981875</td>\n","      <td>1.032155</td>\n","      <td>1.186068</td>\n","      <td>-0.427544</td>\n","      <td>1.184071</td>\n","      <td>2.334574</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.295700</td>\n","      <td>0.227694</td>\n","      <td>1.840403</td>\n","      <td>0.451946</td>\n","      <td>1.281985</td>\n","      <td>0.808997</td>\n","      <td>0.663351</td>\n","      <td>0.226796</td>\n","      <td>0.401404</td>\n","      <td>-0.319276</td>\n","      <td>0.362177</td>\n","      <td>0.449601</td>\n","      <td>-0.037874</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>173</th>\n","      <td>0.876275</td>\n","      <td>2.974543</td>\n","      <td>0.305159</td>\n","      <td>0.301803</td>\n","      <td>-0.332922</td>\n","      <td>-0.985614</td>\n","      <td>-1.424900</td>\n","      <td>1.274310</td>\n","      <td>-0.930179</td>\n","      <td>1.142811</td>\n","      <td>-1.392758</td>\n","      <td>-1.231206</td>\n","      <td>-0.021952</td>\n","    </tr>\n","    <tr>\n","      <th>174</th>\n","      <td>0.493343</td>\n","      <td>1.412609</td>\n","      <td>0.414820</td>\n","      <td>1.052516</td>\n","      <td>0.158572</td>\n","      <td>-0.793334</td>\n","      <td>-1.284344</td>\n","      <td>0.549108</td>\n","      <td>-0.316950</td>\n","      <td>0.969783</td>\n","      <td>-1.129518</td>\n","      <td>-1.485445</td>\n","      <td>0.009893</td>\n","    </tr>\n","    <tr>\n","      <th>175</th>\n","      <td>0.332758</td>\n","      <td>1.744744</td>\n","      <td>-0.389355</td>\n","      <td>0.151661</td>\n","      <td>1.422412</td>\n","      <td>-1.129824</td>\n","      <td>-1.344582</td>\n","      <td>0.549108</td>\n","      <td>-0.422075</td>\n","      <td>2.224236</td>\n","      <td>-1.612125</td>\n","      <td>-1.485445</td>\n","      <td>0.280575</td>\n","    </tr>\n","    <tr>\n","      <th>176</th>\n","      <td>0.209232</td>\n","      <td>0.227694</td>\n","      <td>0.012732</td>\n","      <td>0.151661</td>\n","      <td>1.422412</td>\n","      <td>-1.033684</td>\n","      <td>-1.354622</td>\n","      <td>1.354888</td>\n","      <td>-0.229346</td>\n","      <td>1.834923</td>\n","      <td>-1.568252</td>\n","      <td>-1.400699</td>\n","      <td>0.296498</td>\n","    </tr>\n","    <tr>\n","      <th>177</th>\n","      <td>1.395086</td>\n","      <td>1.583165</td>\n","      <td>1.365208</td>\n","      <td>1.502943</td>\n","      <td>-0.262708</td>\n","      <td>-0.392751</td>\n","      <td>-1.274305</td>\n","      <td>1.596623</td>\n","      <td>-0.422075</td>\n","      <td>1.791666</td>\n","      <td>-1.524378</td>\n","      <td>-1.428948</td>\n","      <td>-0.595160</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>178 rows × 13 columns</p>\n","</div>"],"text/plain":["      alcohol  malic_acid  ...  od280/od315_of_diluted_wines   proline\n","0    1.518613   -0.562250  ...                      1.847920  1.013009\n","1    0.246290   -0.499413  ...                      1.113449  0.965242\n","2    0.196879    0.021231  ...                      0.788587  1.395148\n","3    1.691550   -0.346811  ...                      1.184071  2.334574\n","4    0.295700    0.227694  ...                      0.449601 -0.037874\n","..        ...         ...  ...                           ...       ...\n","173  0.876275    2.974543  ...                     -1.231206 -0.021952\n","174  0.493343    1.412609  ...                     -1.485445  0.009893\n","175  0.332758    1.744744  ...                     -1.485445  0.280575\n","176  0.209232    0.227694  ...                     -1.400699  0.296498\n","177  1.395086    1.583165  ...                     -1.428948 -0.595160\n","\n","[178 rows x 13 columns]"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"IzvhtjGlbrvT","colab_type":"text"},"source":["\n","\n","---\n","\n","### Questão 2.\n","\n","Agora para classificar os modelos que serão testados, implemente a função `evaluate_model()` prototipada abaixo. Essa função recebe um modelo de classificador genérico (`model`). Isso pode ser feito pois o Python trata funções como funções de primeira classe. Isso é, funções podem ser tratadas como variáveis, passadas como parâmetro etc. Avalie a acurácia do modelo utilizando 10-fold cross-validation estratificado (`sklearn.model_selection.StratifiedKFold`), retornando a média das 10 acurácias. O parâmetro `X` indica os dados e `y` os labels."]},{"cell_type":"code","metadata":{"id":"Akd-b1BOZ0gh","colab_type":"code","colab":{}},"source":["from numpy import mean\n","from sklearn.model_selection import StratifiedKFold\n","\n","def evaluate_model(model, X, y):\n","  # Splitting the dataset using the 10-fold cross-validation\n","  skf = StratifiedKFold(n_splits=10)\n","  parts = skf.split(X, y)\n","\n","  # Testing the model\n","  score = []\n","  for train_idx, test_idx in parts:\n","    # - training\n","    model = model.fit(X[train_idx], y[train_idx])\n","    \n","    # - testing\n","    score.append(model.score(X[test_idx], y[test_idx]))\n","\n","  # Returning the mean accuracy score\n","  return(mean(score)) "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wfBVl9qHcamg","colab_type":"text"},"source":["\n","\n","---\n","\n","### Questão 3.\n","\n","Agora para estruturar e organizar melhor nossos testes, vamos utilizar as estruturas de dicionário do Python. Por exemplo, se formos definir dois modelos de Multi-Layer Perceptron, podemos escrever:\n","\n","```\n","experimentos = { \n","    \"MLP camada escondida (5,)\" : MLPClassifier(hidden_layer_sizes=(5,)),\n","    \"MLP camada escondida (5,5)\" : MLPClassifier(hidden_layer_sizes=(5,5))      \n","}\n","```\n","Portanto, defina um dicionário de experimentos com ao menos 3 modelos de SVM (`sklearn.svm.SVC`) e 3 modelos de MLP (`sklearn.neural_network.MLPClassifier`). Para isso varie parâmetros como tipo de kernel e grau do polinômio (para kernels polinomiais) no caso da SVM e no caso das MLPs varie o número de camadas escondidas."]},{"cell_type":"code","metadata":{"id":"ppKAeuZ4c9cN","colab_type":"code","colab":{}},"source":["from sklearn.neural_network import MLPClassifier\n","from sklearn.svm import SVC\n","\n","experiments = { \n","    \"SVM Linear\" : SVC(kernel='poly',degree=1),\n","    \"SVM 2-Poly\" : SVC(kernel='poly',degree=2),\n","    \"SVM 3-Poly\" : SVC(kernel='poly',degree=3),\n","    \"MLP 1-HL\" : MLPClassifier(hidden_layer_sizes=(6,),solver='lbfgs'),\n","    \"MLP 3-HL\" : MLPClassifier(hidden_layer_sizes=(6,6,6,),solver='lbfgs'),  \n","    \"MLP 6-HL\" : MLPClassifier(hidden_layer_sizes=(6,6,6,6,6,6,),solver='lbfgs'),\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FQ4-s6Y-co2d","colab_type":"text"},"source":["\n","\n","---\n","\n","### Questão 4.\n","\n","Para cada modelo instanciado na Questão 3, utilize a função criada na questão 2 para calcular sua acurácia. Exiba o nome do modelo e sua acurácia e determine qual o melhor classificador dentre os especificados."]},{"cell_type":"code","metadata":{"id":"QhISebrhbMqN","colab_type":"code","outputId":"7fac02f8-62b7-44ab-b4ce-e2a4955aaab2","executionInfo":{"status":"ok","timestamp":1586535991833,"user_tz":180,"elapsed":3491,"user":{"displayName":"Matheus Aparecido do Carmo Alves","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GggQ0cnRDkbIVXrd3dqDLpYEUKIr45sRt4MbXAsFg=s64","userId":"02630764298191608861"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["for model_name in experiments:\n","  print(model_name,':',evaluate_model(experiments[model_name],wine_data,wine_dataset.target))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["SVM Linear : 0.9774509803921567\n","SVM 2-Poly : 0.8823529411764707\n","SVM 3-Poly : 0.949673202614379\n","MLP 1-HL : 0.961111111111111\n","MLP 3-HL : 0.9722222222222221\n","MLP 6-HL : 0.7918300653594772\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9dDgC_qGUHIs","colab_type":"text"},"source":["**RESPOSTA:**"]},{"cell_type":"markdown","metadata":{"id":"-2oJ-IXAZEf8","colab_type":"text"},"source":["O melhor classificador para cada método aplicado é o SVM Linear e o MPL com apenas uma camada oculta. Como estamos tratando de um problema relativamente simples de classificação e nossa base de dados não é grande, os resultados obtidos do MLP mostram que a utilização de poucos nós é suficiente e que a adição de mais camadas não necessariamente aprimora a performance da rede neural.  Adicionalmente, um ponto que pode-se avaliar ao ver os resultados do SVC é que a separação linear é suficientemente boa na utilização de um kernel polinomial uma vez que os dados são demasiado poucos e simples para exigirem um grande grau de flexibilização do limite de decisão.\n","\n"]},{"cell_type":"code","metadata":{"id":"p4qXB8z42FLX","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}